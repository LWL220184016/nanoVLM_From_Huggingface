{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2de5dd1f",
      "metadata": {
        "id": "2de5dd1f"
      },
      "source": [
        "### Train a ALM in Google Colab!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OCooV08mNANR",
      "metadata": {
        "id": "OCooV08mNANR"
      },
      "source": [
        "### Clone the repository if you don't have it already"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ooQMjmrMLn-4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooQMjmrMLn-4",
        "outputId": "8c6bb42c-5f61-476d-ac58-6dad176ef4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'nanoVLM_From_Huggingface' already exists and is not an empty directory.\n",
            "/content/nanoVLM_From_Huggingface\n",
            "assets\t\t\tdebug_func.py\t\t\t\t  nanoALM.ipynb\n",
            "benchmark-inference.py\tdebug_tokenizer_dataset_compatibility.py  __pycache__\n",
            "benchmark_suite.py\tgenerate.py\t\t\t\t  README.md\n",
            "checkpoints\t\tmeasure_vram.py\t\t\t\t  train.py\n",
            "data\t\t\tmodels\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('nanoALM'):\n",
        "    !git clone https://github.com/LWL220184016/nanoVLM_From_Huggingface.git\n",
        "%cd nanoVLM_From_Huggingface/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mMhc9OCENup5",
      "metadata": {
        "id": "mMhc9OCENup5"
      },
      "source": [
        "### Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "54bc8463",
      "metadata": {
        "id": "54bc8463"
      },
      "outputs": [],
      "source": [
        "# Let's authentificate with the Hugging Face Hub so you can push your model\n",
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()\n",
        "# !huggingface-cli login\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bcw8qQqoOSR7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bcw8qQqoOSR7",
        "outputId": "8ed6585a-a516-4ed4-b3da-f1c50e61b378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2025.3.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "# If you get an \"Error\" from pip's dependency resolver but the cell complets fine, this is not an issue, you can continue :)\n",
        "!pip -q install torch\n",
        "!pip -q install gcsfs\n",
        "!pip -q install tqdm\n",
        "!pip -q install huggingface_hub\n",
        "!pip -q install librosa\n",
        "!pip install --upgrade datasets\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5e8dc5ba",
      "metadata": {
        "id": "5e8dc5ba"
      },
      "outputs": [],
      "source": [
        "# Decide on the name of your model here!\n",
        "# You will need your HF user name and the name you want to give to it\n",
        "# For me, this would be \"lusxvr/nanoALM\"\n",
        "# hf_model_name = \"YOUR_HF_USER_NAME/nanoALM\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OTsl1jZrMeaJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTsl1jZrMeaJ",
        "outputId": "8bc0d771-7d20-486b-ab1a-ab7bd2bcc966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# nanoALM Imports (please check out the implementations in detail, that's where all the interessting stuff is!)\n",
        "from data.collators import AlignmentCollator, AudioQACollator, SAVEECollator\n",
        "from data.datasets import SAVEEDataset, AudioQADataset\n",
        "from data.processors import get_audio_processor\n",
        "from data.processors import get_tokenizer\n",
        "from models.audio_language_model import AudioLanguageModel\n",
        "import models.utils as utils\n",
        "\n",
        "# Libraries\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "#Otherwise, the tokenizer will through a warning\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "trained_model = None\n",
        "\n",
        "# To reload the modules if you change something in the code\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4Vzo03IzN3Zf",
      "metadata": {
        "id": "4Vzo03IzN3Zf"
      },
      "source": [
        "### Get the dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3Zzn2FI2N7Aj",
      "metadata": {
        "id": "3Zzn2FI2N7Aj"
      },
      "outputs": [],
      "source": [
        "def get_dataloaders(train_cfg, alm_cfg):\n",
        "    # Create datasets\n",
        "    audio_processor = get_audio_processor(alm_cfg)\n",
        "    tokenizer = get_tokenizer(alm_cfg.lm_tokenizer)\n",
        "\n",
        "    # text = \"splitting datasets, disable in get_dataloaders function\"\n",
        "    # print(f\"\\n\\033[38;5;05m{text}05m\\033[0m\")\n",
        "    # Load and combine all training datasets\n",
        "    combined_train_data = []\n",
        "    for dataset_name in train_cfg.train_dataset_name:\n",
        "        train_ds = load_dataset(\n",
        "        path = train_cfg.train_dataset_path,\n",
        "        name = dataset_name,\n",
        "    )\n",
        "        combined_train_data.append(train_ds['train'])\n",
        "    train_ds = concatenate_datasets(combined_train_data)\n",
        "\n",
        "    test_ds = load_dataset(train_cfg.test_dataset_path)\n",
        "    train_ds = train_ds.shuffle(seed=0) # Shuffle the training dataset, so train and val get equal contributions from all concatinated datasets\n",
        "\n",
        "    # Apply cutoff if specified\n",
        "    if train_cfg.data_cutoff_idx is None:\n",
        "        total_samples = len(train_ds)  # Use the entire dataset\n",
        "    else:\n",
        "        total_samples = min(len(train_ds), train_cfg.data_cutoff_idx)\n",
        "\n",
        "    val_size = int(total_samples * train_cfg.val_ratio)\n",
        "    train_size = total_samples - val_size\n",
        "\n",
        "    train_dataset = AudioQADataset(train_ds.select(range(train_size)), tokenizer, audio_processor)\n",
        "    val_dataset = AudioQADataset(train_ds.select(range(train_size, total_samples)), tokenizer, audio_processor)\n",
        "    test_dataset = SAVEEDataset(test_ds, tokenizer, audio_processor)\n",
        "\n",
        "    # Create collators\n",
        "    alignment_collator = AlignmentCollator(tokenizer, alm_cfg.lm_max_length)\n",
        "    aqa_collator = AudioQACollator(tokenizer, alm_cfg.lm_max_length)\n",
        "    savee_collator = SAVEECollator(tokenizer)\n",
        "\n",
        "    # Create dataloaders\n",
        "    alignment_train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=train_cfg.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=alignment_collator,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=train_cfg.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=aqa_collator,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=train_cfg.batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=aqa_collator,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=train_cfg.savee_batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=savee_collator,\n",
        "        pin_memory=True,\n",
        "        )\n",
        "\n",
        "    return alignment_train_loader, train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D7NIuEDuOuuJ",
      "metadata": {
        "id": "D7NIuEDuOuuJ"
      },
      "source": [
        "### Prepare the testing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9fnh6wOlOzat",
      "metadata": {
        "id": "9fnh6wOlOzat"
      },
      "outputs": [],
      "source": [
        "def test_savee(model, tokenizer, test_loader, device):\n",
        "    total_examples = 0\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            audio = batch['audios'].to(device)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            correct_answer = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "            gen = model.generate(input_ids, audio, attention_mask)\n",
        "            model_output = tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
        "\n",
        "            is_correct = utils.check_multiple_choice_with_regex(model_output, correct_answer)\n",
        "\n",
        "            total_examples += len(is_correct)\n",
        "            if is_correct:\n",
        "                correct_predictions += sum(is_correct)\n",
        "    accuracy = correct_predictions / total_examples if total_examples > 0 else 0\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe359194",
      "metadata": {
        "id": "fe359194"
      },
      "source": [
        "### Add debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5d7b7e46",
      "metadata": {
        "id": "5d7b7e46"
      },
      "outputs": [],
      "source": [
        "# 在训练开始前添加这个检查函数\n",
        "def debug_model_dimensions(model, input_ids, audio):\n",
        "    \"\"\"调试模型各层的维度\"\"\"\n",
        "    print(\"=== Model Dimension Debug ===\")\n",
        "\n",
        "    # 检查音频编码器\n",
        "    audio_features = model.audio_encoder.forward(audio, output_hidden_states=True)\n",
        "    print(f\"Audio features shape: {audio_features.shape}\")\n",
        "\n",
        "    # 检查模态投影器\n",
        "    audio_embeds = model.MP(audio_features)\n",
        "    print(f\"Audio embeds shape: {audio_embeds.shape}\")\n",
        "\n",
        "    # 检查文本嵌入\n",
        "    text_embeds = model.decoder.token_embedding(input_ids)\n",
        "    print(f\"Text embeds shape: {text_embeds.shape}\")\n",
        "\n",
        "    # 检查拼接后的嵌入\n",
        "    inputs_embeds = torch.cat([audio_embeds, text_embeds], dim=1)\n",
        "    print(f\"Combined embeds shape: {inputs_embeds.shape}\")\n",
        "\n",
        "    # 检查语言模型输出\n",
        "    logits = model.decoder(inputs_embeds)\n",
        "    print(f\"Logits shape: {logits.shape}\")\n",
        "    print(f\"Vocab size (last dim): {logits.shape[-1]}\")\n",
        "\n",
        "    # 检查语言模型配置\n",
        "    print(f\"LM vocab size config: {model.cfg.lm_vocab_size}\")\n",
        "    print(f\"Decoder vocab size: {getattr(model.decoder, 'vocab_size', 'Not found')}\")\n",
        "\n",
        "    return logits.shape[-1]\n",
        "\n",
        "# 在训练循环开始前调用\n",
        "# vocab_size = debug_model_dimensions(model, input_ids, audios)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2d48d0df",
      "metadata": {
        "id": "2d48d0df"
      },
      "outputs": [],
      "source": [
        "def debug_training_step(model, input_ids, audios, attention_mask, labels):\n",
        "    \"\"\"调试训练步骤\"\"\"\n",
        "    # 添加这些调试行：\n",
        "    print(f\"Batch debug - input_ids shape: {input_ids.shape}, max: {input_ids.max().item()}\")\n",
        "    print(f\"Batch debug - labels shape: {labels.shape}, max: {labels.max().item()}\")\n",
        "    print(f\"Batch debug - Model vocab config: {model.cfg.lm_vocab_size}\")\n",
        "\n",
        "    # 检查decoder的实际vocab_size\n",
        "    if hasattr(model.decoder, 'head') and hasattr(model.decoder.head, 'out_features'):\n",
        "        print(f\"Decoder head in_features: {model.decoder.head.in_features}\")\n",
        "        print(f\"Decoder head out_features: {model.decoder.head.out_features}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_F8u3MJ6PAfd",
      "metadata": {
        "id": "_F8u3MJ6PAfd"
      },
      "source": [
        "### Prepare the training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f3dce46",
      "metadata": {
        "id": "2f3dce46"
      },
      "source": [
        "#### Supervised learning and Generative Training 監督學習生成式訓練"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KxOtMU5zPD-4",
      "metadata": {
        "id": "KxOtMU5zPD-4"
      },
      "outputs": [],
      "source": [
        "def get_lr(it, max_lr, max_steps):\n",
        "    min_lr = max_lr * 0.1\n",
        "    warmup_steps = max_steps * 0.03\n",
        "    # 1) linear warmup for warmup_iters steps\n",
        "    if it < warmup_steps:\n",
        "        return max_lr * (it+1) / warmup_steps\n",
        "    # 2) if it > lr_decay_iters, return min learning rate\n",
        "    if it > max_steps:\n",
        "        return min_lr\n",
        "    # 3) in between, use cosine decay down to min learning rate\n",
        "    decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff starts at 1 and goes to 0\n",
        "    return min_lr + coeff * (max_lr - min_lr)\n",
        "\n",
        "def train(train_cfg, alm_cfg):\n",
        "    alignment_train_loader, train_loader, val_loader, test_loader = get_dataloaders(train_cfg, alm_cfg)\n",
        "    tokenizer = get_tokenizer(alm_cfg.lm_tokenizer)\n",
        "\n",
        "    # Initialize model\n",
        "    if train_cfg.resume_from_alm_checkpoint:\n",
        "        model = AudioLanguageModel.from_pretrained(alm_cfg.alm_checkpoint_path)\n",
        "    else:\n",
        "        model = AudioLanguageModel(alm_cfg)\n",
        "\n",
        "    print(f\"nanoALM initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "    print(f\"Training summary: {len(train_loader.dataset)} samples, {len(train_loader)} batches/epoch, batch size {train_cfg.batch_size}\")\n",
        "\n",
        "    # Define optimizer groups\n",
        "    param_groups = [{'params': model.MP.parameters(), 'lr': train_cfg.lr_mp},\n",
        "                    {'params': list(model.decoder.parameters()) + list(model.audio_encoder.parameters()), 'lr': train_cfg.lr_backbones}]\n",
        "    optimizer = optim.AdamW(param_groups)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    if train_cfg.compile:\n",
        "        model = torch.compile(model)\n",
        "\n",
        "    epoch_times = []\n",
        "    batch_losses = []\n",
        "    val_losses = []\n",
        "    val_plot_steps = []\n",
        "    best_accuracy = 0\n",
        "    global_step = 0\n",
        "    for epoch in range(train_cfg.epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        total_tokens_processed = 0\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "            batch_start_time = time.time()\n",
        "            audios = batch[\"audio\"].to(device)\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            # debug_model_dimensions(model, input_ids, audios)  # Debug model dimensions with dummy data\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.autocast(device_type='cuda', dtype=torch.float16): # Mixed precision training\n",
        "                # debug_training_step(model, input_ids, audios, attention_mask, labels)  # Debug training step\n",
        "                _, loss = model(input_ids, audios, attention_mask=attention_mask, targets=labels)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            adj_lr_mp = get_lr(global_step, train_cfg.lr_mp, len(train_loader) * train_cfg.epochs)\n",
        "            adj_lr_backbones = get_lr(global_step, train_cfg.lr_backbones, len(train_loader) * train_cfg.epochs)\n",
        "            optimizer.param_groups[0]['lr'] = adj_lr_mp\n",
        "            optimizer.param_groups[1]['lr'] = adj_lr_backbones\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_loss = loss.item()\n",
        "            total_train_loss += batch_loss\n",
        "            batch_losses.append(batch_loss)\n",
        "\n",
        "            num_tokens = torch.sum(attention_mask).item()\n",
        "            # 修改音頻token計算：根據實際的音頻處理方式\n",
        "            audio_tokens = audios.shape[0] * alm_cfg.mp_target_length  # 使用配置的目標長度\n",
        "            num_tokens += audio_tokens\n",
        "            total_tokens_processed += num_tokens\n",
        "\n",
        "            batch_end_time = time.time()\n",
        "            batch_duration = batch_end_time - batch_start_time\n",
        "            tokens_per_second = num_tokens / batch_duration\n",
        "\n",
        "            if global_step % 5 == 0:\n",
        "                model.eval()\n",
        "                torch.cuda.empty_cache()  # Clear GPU memory\n",
        "                with torch.no_grad():\n",
        "                    total_val_loss = 0\n",
        "                    for batch in val_loader:\n",
        "                        audios = batch[\"audio\"].to(device)\n",
        "                        input_ids = batch[\"input_ids\"].to(device)\n",
        "                        labels = batch[\"labels\"].to(device)\n",
        "                        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "                        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                            # debug_training_step(model, input_ids, audios, attention_mask, labels)  # Debug training step\n",
        "                            _, loss = model(input_ids, audios, attention_mask=attention_mask, targets=labels)\n",
        "\n",
        "                        total_val_loss += loss.item()\n",
        "                    avg_val_loss = total_val_loss / len(val_loader)\n",
        "                    val_losses.append(avg_val_loss)\n",
        "                    val_plot_steps.append(global_step)\n",
        "                epoch_accuracy = 0\n",
        "                if train_cfg.eval_in_epochs:\n",
        "                    epoch_accuracy = test_savee(model, tokenizer, test_loader, device)\n",
        "                    if epoch_accuracy > best_accuracy:\n",
        "                      best_accuracy = epoch_accuracy\n",
        "                      model.save_pretrained(save_directory=alm_cfg.alm_checkpoint_path)\n",
        "                    print(f\"\\nStep: {global_step}, Loss: {batch_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Tokens/s: {tokens_per_second:.2f}, Accuracy: {epoch_accuracy:.4f}\")\n",
        "                model.train()\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_duration = epoch_end_time - epoch_start_time\n",
        "        epoch_times.append(epoch_duration)\n",
        "\n",
        "        epoch_tokens_per_second = total_tokens_processed / epoch_duration\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{train_cfg.epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Time: {epoch_duration:.2f}s | T/s: {epoch_tokens_per_second:.2f}\")\n",
        "\n",
        "    # Summary Statistics\n",
        "    if not train_cfg.eval_in_epochs:\n",
        "        model.save_pretrained(save_directory=alm_cfg.alm_checkpoint_path)\n",
        "    try:\n",
        "        model.push_to_hub(hf_model_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error pushing model to hub: {e}\")\n",
        "\n",
        "    avg_epoch_time = sum(epoch_times) / len(epoch_times)\n",
        "    total_training_time = sum(epoch_times)\n",
        "    total_samples_processed = len(train_loader.dataset) * train_cfg.epochs\n",
        "    avg_time_per_sample = total_training_time / total_samples_processed\n",
        "    print(f\"Average time per epoch: {avg_epoch_time:.2f}s\")\n",
        "    print(f\"Average time per sample: {avg_time_per_sample:.4f}s\")\n",
        "\n",
        "    plt.plot(batch_losses, label='Train Loss')\n",
        "    plt.plot(val_plot_steps, val_losses, label='Val Loss')\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Curve')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "    # With this code you can test the accuracy of the model on the SAVEE dataset\n",
        "    # But if you only train with few samples, the accuracy will be very low\n",
        "    # print(\"Testing SAVEE Accuracy:\")\n",
        "    # accuracy = test_savee(model, tokenizer, test_loader, device)\n",
        "    # print(f\"SAVEE Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04da5b01",
      "metadata": {
        "id": "04da5b01"
      },
      "source": [
        "#### Three-stage training (contrast training, generative training, instruction fine-tuning) 三段式訓練(對比訓練, 生成式訓練, 指令微調)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb323c8",
      "metadata": {
        "id": "fbb323c8"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from debug_func import debug_contrastive_learning\n",
        "\n",
        "# 改進對比學習訓練\n",
        "def contrastive_loss(audio_embeds, text_embeds, temperature=0.07):\n",
        "    \"\"\"\n",
        "    標準、高效的對比學習損失 (CLIP Loss)。\n",
        "    注意：輸入的 embeds 應該是池化後的 [B, D] 維度向量。\n",
        "    \"\"\"\n",
        "    # 歸一化\n",
        "    audio_embeds = F.normalize(audio_embeds, p=2, dim=-1)\n",
        "    text_embeds = F.normalize(text_embeds, p=2, dim=-1)\n",
        "\n",
        "    # 計算相似度矩陣\n",
        "    # temperature 是一個重要的超參數，CLIP 論文中是可學習的，但固定值也可以\n",
        "    logits_per_audio = torch.matmul(audio_embeds, text_embeds.T) / temperature\n",
        "    logits_per_text = logits_per_audio.T\n",
        "\n",
        "    # 創建標籤 (0, 1, 2, ..., B-1)\n",
        "    labels = torch.arange(audio_embeds.shape[0]).to(logits_per_audio.device)\n",
        "\n",
        "    # 對稱的交叉熵損失\n",
        "    loss_a = F.cross_entropy(logits_per_audio, labels)\n",
        "    loss_t = F.cross_entropy(logits_per_text, labels)\n",
        "    \n",
        "    total_loss = (loss_a + loss_t) / 2\n",
        "    \n",
        "    # 監控指標 (可選但推薦)\n",
        "    with torch.no_grad():\n",
        "        pos_sim = torch.diagonal(logits_per_audio * temperature).mean()\n",
        "        mask = ~torch.eye(labels.shape[0], dtype=torch.bool, device=labels.device)\n",
        "        neg_sim = (logits_per_audio * temperature)[mask].mean()\n",
        "\n",
        "    return total_loss, {\n",
        "        \"loss\": total_loss.item(),\n",
        "        \"pos_sim\": pos_sim.item(), # 正樣本對的餘弦相似度\n",
        "        \"neg_sim\": neg_sim.item()  # 負樣本對的餘弦相似度\n",
        "    }\n",
        "\n",
        "def train_stage1_alignment_corrected(train_cfg, alm_cfg):\n",
        "    \n",
        "    # 直接初始化模型\n",
        "    model = AudioLanguageModel(alm_cfg)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # 凍結音頻編碼器和語言模型\n",
        "    model.audio_encoder.requires_grad_(False)\n",
        "    model.decoder.requires_grad_(False)\n",
        "    model.MP.requires_grad_(True)\n",
        "    \n",
        "    alignment_train_loader, _, val_loader, _ = get_dataloaders(train_cfg, alm_cfg)\n",
        "    \n",
        "    optimizer = optim.AdamW(model.MP.parameters(), lr=train_cfg.lr_mp, weight_decay=0.01)\n",
        "    # 可選：添加學習率調度器，如 warmup\n",
        "    \n",
        "    best_alignment = 0\n",
        "    \n",
        "    for epoch in range(train_cfg.stage1_epochs):\n",
        "        model.train()\n",
        "        for batch in tqdm(alignment_train_loader, desc=f\"Stage1 Epoch {epoch+1}\"):\n",
        "            audios = batch[\"audio\"].to(device)\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device) # 需要 attention_mask\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # 1. 音頻編碼 -> 投影\n",
        "            with torch.no_grad():\n",
        "                audio_features = model.audio_encoder(audios).last_hidden_state\n",
        "            projected_audio_features = model.MP(audio_features)\n",
        "            \n",
        "            # 2. 文本編碼 (!!! 關鍵修正 !!!)\n",
        "            with torch.no_grad():\n",
        "                text_outputs = model.decoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                text_features = text_outputs.last_hidden_state # [B, S, D]\n",
        "\n",
        "            # 3. 池化操作 (Pooling)\n",
        "            # 音頻池化\n",
        "            audio_pooled = projected_audio_features.mean(dim=1) # [B, D]\n",
        "            # 文本池化 (注意要忽略 padding)\n",
        "            last_hidden = text_features\n",
        "            # 根據 attention_mask 來安全地做平均池化\n",
        "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size()).float()\n",
        "            sum_embeddings = torch.sum(last_hidden * input_mask_expanded, 1)\n",
        "            sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "            text_pooled = sum_embeddings / sum_mask # [B, D]\n",
        "\n",
        "            # 4. 計算簡化後的對比損失\n",
        "            loss, metrics = contrastive_loss(audio_pooled, text_pooled)\n",
        "            \n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.MP.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_train_loss += loss.item()\n",
        "            \n",
        "        avg_train_loss = total_train_loss / len(alignment_train_loader)\n",
        "        print(f\"Stage1 Epoch {epoch+1}: Contrastive Loss {avg_train_loss:.4f}\")\n",
        "        \n",
        "        # 每5個epoch驗證一次\n",
        "        if epoch % 5 == 0:\n",
        "            model.eval()\n",
        "            total_alignment_score = 0\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                for i, batch in enumerate(val_loader):\n",
        "                    if i >= 20:  # 只驗證前20個batch以節省時間\n",
        "                        break\n",
        "                    audios = batch[\"audio\"].to(device)\n",
        "                    input_ids = batch[\"input_ids\"].to(device)\n",
        "                    alignment_score = model.validate_audio_text_alignment(input_ids, audios)\n",
        "                    total_alignment_score += alignment_score\n",
        "            \n",
        "            avg_alignment = total_alignment_score / min(20, len(val_loader))\n",
        "            print(f\"Epoch {epoch}: Average alignment score: {avg_alignment:.4f}\")\n",
        "            \n",
        "            if avg_alignment > best_alignment:\n",
        "                best_alignment = avg_alignment\n",
        "                patience = 0\n",
        "                model.save_pretrained(save_directory=f\"{alm_cfg.alm_checkpoint_path}/stage1_best\")\n",
        "                print(f\"  New best alignment: {best_alignment:.4f}\")\n",
        "            else:\n",
        "                patience += 1\n",
        "            \n",
        "            model.train()\n",
        "    \n",
        "    print(f\"Stage 1 completed! Best alignment: {best_alignment:.4f}\")\n",
        "    return model\n",
        "\n",
        "def train_step2_pretraining(train_cfg, alm_cfg, stage1_model=None):\n",
        "    \"\"\"第二步：语言模型预训练\"\"\"\n",
        "    print(\"=== Stage 2: Language Model Pretraining ===\")\n",
        "\n",
        "    train_loader, val_loader, test_loader = get_dataloaders(train_cfg, alm_cfg)\n",
        "    tokenizer = get_tokenizer(alm_cfg.lm_tokenizer)\n",
        "\n",
        "    # 加载第一阶段模型或从头开始\n",
        "    if stage1_model is not None:\n",
        "        model = stage1_model\n",
        "    else:\n",
        "        try:\n",
        "            model = AudioLanguageModel.from_pretrained(f\"{alm_cfg.alm_checkpoint_path}/stage1_final\")\n",
        "            print(\"Loaded Stage 1 model\")\n",
        "        except:\n",
        "            model = AudioLanguageModel(alm_cfg)\n",
        "            print(\"Starting Stage 2 from scratch\")\n",
        "\n",
        "    # 冻结音频编码器，解冻语言模型和模态投影器\n",
        "    for param in model.audio_encoder.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.decoder.parameters():\n",
        "        param.requires_grad = True\n",
        "    for param in model.MP.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Stage 2: Training {trainable_params:,} parameters\")\n",
        "\n",
        "    # 不同学习率\n",
        "    param_groups = [\n",
        "        {'params': model.MP.parameters(), 'lr': train_cfg.lr_mp * 0.1},\n",
        "        {'params': model.decoder.parameters(), 'lr': train_cfg.lr_backbones}\n",
        "    ]\n",
        "    optimizer = optim.AdamW(param_groups)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    if train_cfg.compile:\n",
        "        model = torch.compile(model)\n",
        "\n",
        "    batch_losses = []\n",
        "    val_losses = []\n",
        "    val_plot_steps = []\n",
        "    best_loss = float('inf')\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(train_cfg.stage2_epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Stage2 Epoch {epoch+1}\"):\n",
        "            audios = batch[\"audio\"].to(device)\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                # 使用因果语言建模损失\n",
        "                _, loss = model(input_ids, audios, attention_mask=attention_mask, targets=labels)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # 动态学习率调整\n",
        "            adj_lr_mp = get_lr(global_step, train_cfg.lr_mp * 0.1, len(train_loader) * train_cfg.stage2_epochs)\n",
        "            adj_lr_backbones = get_lr(global_step, train_cfg.lr_backbones, len(train_loader) * train_cfg.stage2_epochs)\n",
        "            optimizer.param_groups[0]['lr'] = adj_lr_mp\n",
        "            optimizer.param_groups[1]['lr'] = adj_lr_backbones\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_loss = loss.item()\n",
        "            total_train_loss += batch_loss\n",
        "            batch_losses.append(batch_loss)\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "        if avg_train_loss < best_loss:\n",
        "            best_loss = avg_train_loss\n",
        "            model.save_pretrained(save_directory=f\"{alm_cfg.alm_checkpoint_path}/stage2_best\")\n",
        "\n",
        "    # 保存第二阶段模型\n",
        "    model.save_pretrained(save_directory=f\"{alm_cfg.alm_checkpoint_path}/stage2_final\")\n",
        "    print(\"Stage 2 completed!\")\n",
        "    plt.plot(batch_losses, label='Train Loss')\n",
        "    plt.plot(val_plot_steps, val_losses, label='Val Loss')\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Curve')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_step3_instruction_tuning(train_cfg, alm_cfg, stage2_model=None):\n",
        "    \"\"\"第三步：指令微调\"\"\"\n",
        "    print(\"=== Stage 3: Instruction Tuning ===\")\n",
        "\n",
        "    train_loader, val_loader, test_loader = get_dataloaders(train_cfg, alm_cfg)\n",
        "    tokenizer = get_tokenizer(alm_cfg.lm_tokenizer)\n",
        "\n",
        "    # 加载第二阶段模型\n",
        "    if stage2_model is not None:\n",
        "        model = stage2_model\n",
        "    else:\n",
        "        try:\n",
        "            model = AudioLanguageModel.from_pretrained(f\"{alm_cfg.alm_checkpoint_path}/stage2_final\")\n",
        "            print(\"Loaded Stage 2 model\")\n",
        "        except:\n",
        "            print(\"No Stage 2 model found, using current model\")\n",
        "            model = AudioLanguageModel(alm_cfg)\n",
        "\n",
        "    # 全部解冻，使用较小学习率\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    print(f\"Stage 3: Training all {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "\n",
        "    # 更小的学习率\n",
        "    param_groups = [\n",
        "        {'params': model.MP.parameters(), 'lr': train_cfg.lr_mp * 0.01},\n",
        "        {'params': model.decoder.parameters(), 'lr': train_cfg.lr_backbones * 0.1},\n",
        "        {'params': model.audio_encoder.parameters(), 'lr': train_cfg.lr_backbones * 0.01}\n",
        "    ]\n",
        "    optimizer = optim.AdamW(param_groups)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    if train_cfg.compile:\n",
        "        model = torch.compile(model)\n",
        "\n",
        "    # 这里可以使用原来的训练循环，但数据应该是指令格式\n",
        "    # 暂时使用相同的数据格式\n",
        "    best_accuracy = 0\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(train_cfg.stage3_epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Stage3 Epoch {epoch+1}\"):\n",
        "            audios = batch[\"audio\"].to(device)\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                _, loss = model(input_ids, audios, attention_mask=attention_mask, targets=labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_loss = loss.item()\n",
        "            total_train_loss += batch_loss\n",
        "\n",
        "            if global_step % 50 == 0:\n",
        "                print(f\"Stage3 Step: {global_step}, Instruction Loss: {batch_loss:.4f}\")\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "        # 评估性能\n",
        "        if train_cfg.eval_in_epochs:\n",
        "            accuracy = test_savee(model, tokenizer, test_loader, device)\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                model.save_pretrained(save_directory=f\"{alm_cfg.alm_checkpoint_path}/stage3_best\")\n",
        "            print(f\"Stage3 Epoch {epoch+1}/{train_cfg.stage3_epochs} | Loss: {avg_train_loss:.4f} | Accuracy: {accuracy:.4f}\")\n",
        "        else:\n",
        "            print(f\"Stage3 Epoch {epoch+1}/{train_cfg.stage3_epochs} | Instruction Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # 保存最终模型\n",
        "    model.save_pretrained(save_directory=f\"{alm_cfg.alm_checkpoint_path}/final_model\")\n",
        "    print(\"Stage 3 completed!\")\n",
        "    return model\n",
        "\n",
        "def train_three_stages(train_cfg, alm_cfg):\n",
        "    \"\"\"完整的三阶段训练\"\"\"\n",
        "    print(\"Starting Three-Stage Training Pipeline\")\n",
        "\n",
        "    # 第一阶段：模态投影器对齐\n",
        "    stage1_model = train_step1_alignment(train_cfg, alm_cfg)\n",
        "\n",
        "    # 第二阶段：语言模型预训练\n",
        "    stage2_model = train_step2_pretraining(train_cfg, alm_cfg, stage1_model)\n",
        "\n",
        "    # 第三阶段：指令微调\n",
        "    final_model = train_step3_instruction_tuning(train_cfg, alm_cfg, stage2_model)\n",
        "\n",
        "    print(\"=== Training Pipeline Completed! ===\")\n",
        "    return stage1_model, stage2_model, final_model\n",
        "\n",
        "\n",
        "# # 替换原来的训练调用\n",
        "# alm_cfg = ALMConfig()\n",
        "# train_cfg = TrainConfig()\n",
        "\n",
        "# # 运行三阶段训练\n",
        "# final_model = train_three_stages(train_cfg, alm_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KmFQwKGcSLr_",
      "metadata": {
        "id": "KmFQwKGcSLr_"
      },
      "source": [
        "### Lets run the training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "BXUaUEUcJCp2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXUaUEUcJCp2",
        "outputId": "008b47ba-7c01-4a8c-bc1c-66609317895d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory 'checkpoints' already exists.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from models.config import ALMConfig, TrainConfig\n",
        "\n",
        "# 要創建的目錄路徑\n",
        "dir_name = ALMConfig.alm_checkpoint_path\n",
        "\n",
        "try:\n",
        "    os.mkdir(dir_name)\n",
        "    print(f\"Directory '{dir_name}' created successfully.\")\n",
        "except FileExistsError:\n",
        "    print(f\"Directory '{dir_name}' already exists.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Parent directory does not exist for '{dir_name}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9MlFpXQFSNdx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9MlFpXQFSNdx",
        "outputId": "cbf1a333-b862-4535-8b83-afef2b1b28c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Improved Stage 1: Modality Projector Alignment ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AudioProcessor_from_HF initialized with model: <class 'transformers.models.whisper.processing_whisper.WhisperProcessor'>\n",
            "  Target feature frames from cfg: 1500\n",
            "  Using model sampling rate: 16000, hop_length: 160, n_fft: 400\n",
            "  Calculated max raw audio samples for processor: 240240\n",
            "Loading from backbone weights\n",
            "Successfully loaded HuggingFaceTB/SmolLM2-1.7B weights from safetensors. Model has 1,711,376,384 parameters.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n",
            "Stage1 Epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio embeds shape: torch.Size([12, 25, 2048])\n",
            "Text embeds shape: torch.Size([12, 102, 2048])\n",
            "Audio embeds range: [-3.9401, 4.4385]\n",
            "Text embeds range: [-0.8945, 0.9023]\n",
            "Audio pooled shape: torch.Size([12, 2048])\n",
            "Text pooled shape: torch.Size([12, 2048])\n",
            "Audio pooled norm before: 40.5169\n",
            "Text pooled norm before: 2.4322\n",
            "Audio pooled norm after: 1.0000\n",
            "Text pooled norm after: 1.0000\n",
            "Similarity matrix diagonal mean: 0.0306\n",
            "Similarity matrix off-diagonal mean: 0.0284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 1: 100%|██████████| 68/68 [00:32<00:00,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 1: Loss 5.0548\n",
            "  A2T: 2.3189, T2A: 2.3142\n",
            "  Pos Sim: 0.4644, Neg Sim: 0.6693\n",
            "  Variance Loss: 21.0899\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.0530\n",
            "  New best alignment: 0.0530\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 2: 100%|██████████| 68/68 [00:30<00:00,  2.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 2: Loss 4.9390\n",
            "  A2T: 2.2763, T2A: 2.2476\n",
            "  Pos Sim: 0.8857, Neg Sim: 1.1485\n",
            "  Variance Loss: 20.7556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 3: 100%|██████████| 68/68 [00:30<00:00,  2.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 3: Loss 4.9449\n",
            "  A2T: 2.2881, T2A: 2.2413\n",
            "  Pos Sim: 1.1125, Neg Sim: 1.3878\n",
            "  Variance Loss: 20.7735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.0952\n",
            "  New best alignment: 0.0952\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 4: 100%|██████████| 68/68 [00:31<00:00,  2.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 4: Loss 4.8765\n",
            "  A2T: 2.2489, T2A: 2.2152\n",
            "  Pos Sim: 1.3789, Neg Sim: 1.6135\n",
            "  Variance Loss: 20.6246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 5: 100%|██████████| 68/68 [00:30<00:00,  2.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 5: Loss 4.8530\n",
            "  A2T: 2.2380, T2A: 2.2028\n",
            "  Pos Sim: 1.2919, Neg Sim: 1.5304\n",
            "  Variance Loss: 20.6099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.0993\n",
            "  New best alignment: 0.0993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rStage1 Epoch 6:   0%|          | 0/68 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio embeds shape: torch.Size([12, 25, 2048])\n",
            "Text embeds shape: torch.Size([12, 102, 2048])\n",
            "Audio embeds range: [-10.5618, 8.4510]\n",
            "Text embeds range: [-0.8945, 0.9023]\n",
            "Audio pooled shape: torch.Size([12, 2048])\n",
            "Text pooled shape: torch.Size([12, 2048])\n",
            "Audio pooled norm before: 38.1547\n",
            "Text pooled norm before: 2.4951\n",
            "Audio pooled norm after: 1.0000\n",
            "Text pooled norm after: 1.0000\n",
            "Similarity matrix diagonal mean: 0.0837\n",
            "Similarity matrix off-diagonal mean: 0.0426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 6: 100%|██████████| 68/68 [00:31<00:00,  2.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 6: Loss 4.8438\n",
            "  A2T: 2.2377, T2A: 2.1947\n",
            "  Pos Sim: 1.3329, Neg Sim: 1.5560\n",
            "  Variance Loss: 20.5654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 7: 100%|██████████| 68/68 [00:30<00:00,  2.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 7: Loss 4.8312\n",
            "  A2T: 2.2277, T2A: 2.1937\n",
            "  Pos Sim: 1.3651, Neg Sim: 1.5479\n",
            "  Variance Loss: 20.4926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.1013\n",
            "  New best alignment: 0.1013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 8: 100%|██████████| 68/68 [00:31<00:00,  2.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 8: Loss 4.8476\n",
            "  A2T: 2.2296, T2A: 2.2058\n",
            "  Pos Sim: 1.2722, Neg Sim: 1.4732\n",
            "  Variance Loss: 20.6098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 9: 100%|██████████| 68/68 [00:31<00:00,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 9: Loss 4.8747\n",
            "  A2T: 2.2453, T2A: 2.2157\n",
            "  Pos Sim: 1.2454, Neg Sim: 1.4468\n",
            "  Variance Loss: 20.6830\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.1102\n",
            "  New best alignment: 0.1102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 10: 100%|██████████| 68/68 [00:31<00:00,  2.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 10: Loss 4.8570\n",
            "  A2T: 2.2356, T2A: 2.2085\n",
            "  Pos Sim: 1.2386, Neg Sim: 1.4262\n",
            "  Variance Loss: 20.6446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rStage1 Epoch 11:   0%|          | 0/68 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio embeds shape: torch.Size([12, 25, 2048])\n",
            "Text embeds shape: torch.Size([12, 102, 2048])\n",
            "Audio embeds range: [-10.9655, 9.6834]\n",
            "Text embeds range: [-0.8945, 0.9023]\n",
            "Audio pooled shape: torch.Size([12, 2048])\n",
            "Text pooled shape: torch.Size([12, 2048])\n",
            "Audio pooled norm before: 40.4912\n",
            "Text pooled norm before: 2.6122\n",
            "Audio pooled norm after: 1.0000\n",
            "Text pooled norm after: 1.0000\n",
            "Similarity matrix diagonal mean: 0.1006\n",
            "Similarity matrix off-diagonal mean: 0.0494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 11: 100%|██████████| 68/68 [00:31<00:00,  2.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 11: Loss 4.8243\n",
            "  A2T: 2.2213, T2A: 2.1921\n",
            "  Pos Sim: 1.3500, Neg Sim: 1.5435\n",
            "  Variance Loss: 20.5441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.0848\n",
            "  No improvement, patience: 1/10\n",
            "  Increased learning rate to: 1.31e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 12: 100%|██████████| 68/68 [00:31<00:00,  2.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 12: Loss 4.8096\n",
            "  A2T: 2.2105, T2A: 2.1870\n",
            "  Pos Sim: 1.1518, Neg Sim: 1.3186\n",
            "  Variance Loss: 20.6048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 13: 100%|██████████| 68/68 [00:31<00:00,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 13: Loss 4.7846\n",
            "  A2T: 2.1971, T2A: 2.1760\n",
            "  Pos Sim: 1.2067, Neg Sim: 1.3286\n",
            "  Variance Loss: 20.5778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.0801\n",
            "  No improvement, patience: 2/10\n",
            "  Increased learning rate to: 1.06e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 14: 100%|██████████| 68/68 [00:31<00:00,  2.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 14: Loss 4.7534\n",
            "  A2T: 2.1802, T2A: 2.1641\n",
            "  Pos Sim: 1.1148, Neg Sim: 1.2092\n",
            "  Variance Loss: 20.4555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 15: 100%|██████████| 68/68 [00:31<00:00,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 15: Loss 4.7139\n",
            "  A2T: 2.1627, T2A: 2.1428\n",
            "  Pos Sim: 1.1147, Neg Sim: 1.1777\n",
            "  Variance Loss: 20.4223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.0790\n",
            "  No improvement, patience: 3/10\n",
            "  Increased learning rate to: 7.54e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rStage1 Epoch 16:   0%|          | 0/68 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio embeds shape: torch.Size([12, 25, 2048])\n",
            "Text embeds shape: torch.Size([12, 102, 2048])\n",
            "Audio embeds range: [-10.9728, 9.7939]\n",
            "Text embeds range: [-0.8945, 0.9023]\n",
            "Audio pooled shape: torch.Size([12, 2048])\n",
            "Text pooled shape: torch.Size([12, 2048])\n",
            "Audio pooled norm before: 36.7685\n",
            "Text pooled norm before: 2.7002\n",
            "Audio pooled norm after: 1.0000\n",
            "Text pooled norm after: 1.0000\n",
            "Similarity matrix diagonal mean: 0.0674\n",
            "Similarity matrix off-diagonal mean: 0.0310\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 16: 100%|██████████| 68/68 [00:31<00:00,  2.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 16: Loss 4.7081\n",
            "  A2T: 2.1554, T2A: 2.1432\n",
            "  Pos Sim: 1.0364, Neg Sim: 1.0875\n",
            "  Variance Loss: 20.4767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 17: 100%|██████████| 68/68 [00:31<00:00,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 17: Loss 4.7037\n",
            "  A2T: 2.1563, T2A: 2.1379\n",
            "  Pos Sim: 1.0641, Neg Sim: 1.0811\n",
            "  Variance Loss: 20.4731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.0778\n",
            "  No improvement, patience: 4/10\n",
            "  Increased learning rate to: 4.50e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 18: 100%|██████████| 68/68 [00:31<00:00,  2.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 18: Loss 4.6944\n",
            "  A2T: 2.1568, T2A: 2.1286\n",
            "  Pos Sim: 1.0443, Neg Sim: 1.0740\n",
            "  Variance Loss: 20.4482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 19: 100%|██████████| 68/68 [00:31<00:00,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 19: Loss 4.6736\n",
            "  A2T: 2.1422, T2A: 2.1231\n",
            "  Pos Sim: 1.0415, Neg Sim: 1.0628\n",
            "  Variance Loss: 20.4123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.0795\n",
            "  No improvement, patience: 5/10\n",
            "  Increased learning rate to: 1.99e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 20: 100%|██████████| 68/68 [00:31<00:00,  2.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 20: Loss 4.6685\n",
            "  A2T: 2.1428, T2A: 2.1170\n",
            "  Pos Sim: 1.0490, Neg Sim: 1.0750\n",
            "  Variance Loss: 20.4404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rStage1 Epoch 21:   0%|          | 0/68 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio embeds shape: torch.Size([12, 25, 2048])\n",
            "Text embeds shape: torch.Size([12, 102, 2048])\n",
            "Audio embeds range: [-10.9034, 9.2670]\n",
            "Text embeds range: [-0.8945, 0.9023]\n",
            "Audio pooled shape: torch.Size([12, 2048])\n",
            "Text pooled shape: torch.Size([12, 2048])\n",
            "Audio pooled norm before: 33.6400\n",
            "Text pooled norm before: 2.7819\n",
            "Audio pooled norm after: 1.0000\n",
            "Text pooled norm after: 1.0000\n",
            "Similarity matrix diagonal mean: 0.0470\n",
            "Similarity matrix off-diagonal mean: 0.0297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 21: 100%|██████████| 68/68 [00:31<00:00,  2.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 21: Loss 4.6780\n",
            "  A2T: 2.1465, T2A: 2.1216\n",
            "  Pos Sim: 1.0074, Neg Sim: 1.0334\n",
            "  Variance Loss: 20.4969\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.0775\n",
            "  No improvement, patience: 6/10\n",
            "  Increased learning rate to: 4.40e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 22: 100%|██████████| 68/68 [00:31<00:00,  2.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 22: Loss 4.6678\n",
            "  A2T: 2.1387, T2A: 2.1196\n",
            "  Pos Sim: 1.0290, Neg Sim: 1.0382\n",
            "  Variance Loss: 20.4773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 23: 100%|██████████| 68/68 [00:31<00:00,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 23: Loss 4.6723\n",
            "  A2T: 2.1428, T2A: 2.1201\n",
            "  Pos Sim: 1.0260, Neg Sim: 1.0572\n",
            "  Variance Loss: 20.4679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.0712\n",
            "  No improvement, patience: 7/10\n",
            "  Increased learning rate to: 1.50e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 24: 100%|██████████| 68/68 [00:31<00:00,  2.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 24: Loss 4.6803\n",
            "  A2T: 2.1409, T2A: 2.1294\n",
            "  Pos Sim: 1.0421, Neg Sim: 1.0654\n",
            "  Variance Loss: 20.5035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 25: 100%|██████████| 68/68 [00:31<00:00,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 25: Loss 4.6667\n",
            "  A2T: 2.1364, T2A: 2.1205\n",
            "  Pos Sim: 1.0539, Neg Sim: 1.0548\n",
            "  Variance Loss: 20.4902\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.0747\n",
            "  No improvement, patience: 8/10\n",
            "  Increased learning rate to: 1.47e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rStage1 Epoch 26:   0%|          | 0/68 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio embeds shape: torch.Size([12, 25, 2048])\n",
            "Text embeds shape: torch.Size([12, 102, 2048])\n",
            "Audio embeds range: [-12.2827, 10.4915]\n",
            "Text embeds range: [-0.8945, 0.9023]\n",
            "Audio pooled shape: torch.Size([12, 2048])\n",
            "Text pooled shape: torch.Size([12, 2048])\n",
            "Audio pooled norm before: 38.6905\n",
            "Text pooled norm before: 2.8521\n",
            "Audio pooled norm after: 1.0000\n",
            "Text pooled norm after: 1.0000\n",
            "Similarity matrix diagonal mean: 0.0605\n",
            "Similarity matrix off-diagonal mean: 0.0326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 26: 100%|██████████| 68/68 [00:31<00:00,  2.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 26: Loss 4.6507\n",
            "  A2T: 2.1268, T2A: 2.1147\n",
            "  Pos Sim: 0.9833, Neg Sim: 0.9488\n",
            "  Variance Loss: 20.4625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 27: 100%|██████████| 68/68 [00:31<00:00,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 27: Loss 4.6548\n",
            "  A2T: 2.1337, T2A: 2.1112\n",
            "  Pos Sim: 0.9939, Neg Sim: 0.9771\n",
            "  Variance Loss: 20.4977\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.0749\n",
            "  No improvement, patience: 9/10\n",
            "  Increased learning rate to: 1.42e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 28: 100%|██████████| 68/68 [00:31<00:00,  2.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 28: Loss 4.6141\n",
            "  A2T: 2.1080, T2A: 2.0970\n",
            "  Pos Sim: 0.9657, Neg Sim: 0.9082\n",
            "  Variance Loss: 20.4571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 29: 100%|██████████| 68/68 [00:31<00:00,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Epoch 29: Loss 4.6187\n",
            "  A2T: 2.1126, T2A: 2.0967\n",
            "  Pos Sim: 0.9590, Neg Sim: 0.9112\n",
            "  Variance Loss: 20.4720\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Average alignment score: 0.0788\n",
            "  No improvement, patience: 10/10\n",
            "  Increased learning rate to: 1.33e-05\n",
            "Early stopping at epoch 29\n",
            "Stage 1 completed! Best alignment: 0.1102\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Stage 2: Language Model Pretraining ===\n",
            "AudioProcessor_from_HF initialized with model: <class 'transformers.models.whisper.processing_whisper.WhisperProcessor'>\n",
            "  Target feature frames from cfg: 1500\n",
            "  Using model sampling rate: 16000, hop_length: 160, n_fft: 400\n",
            "  Calculated max raw audio samples for processor: 240240\n",
            "Stage 2: Training 1,882,306,048 parameters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stage2 Epoch 1:   0%|          | 0/68 [00:03<?, ?it/s]\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 22.16 GiB of which 11.38 MiB is free. Process 114756 has 22.14 GiB memory in use. Of the allocated memory 21.16 GiB is allocated by PyTorch, and 758.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-13-1145085061.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstage2_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step2_pretraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malm_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage1_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step3_instruction_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malm_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage2_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# stage1_model, stage2_model, final_model = train_three_stages(train_cfg, alm_cfg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-11-1807903766.py\u001b[0m in \u001b[0;36mtrain_step2_pretraining\u001b[0;34m(train_cfg, alm_cfg, stage1_model)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madj_lr_backbones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"betas\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             has_complex = self._init_group(\n\u001b[0m\u001b[1;32m    233\u001b[0m                 \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_init_group\u001b[0;34m(self, group, params_with_grad, grads, amsgrad, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 )\n\u001b[1;32m    170\u001b[0m                 \u001b[0;31m# Exponential moving average of gradient values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 state[\"exp_avg\"] = torch.zeros_like(\n\u001b[0m\u001b[1;32m    172\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 22.16 GiB of which 11.38 MiB is free. Process 114756 has 22.14 GiB memory in use. Of the allocated memory 21.16 GiB is allocated by PyTorch, and 758.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "\n",
        "alm_cfg = ALMConfig()\n",
        "train_cfg = TrainConfig()\n",
        "\n",
        "# trained_model = train(train_cfg, alm_cfg)\n",
        "stage1_model = train_step1_alignment(train_cfg, alm_cfg)\n",
        "\n",
        "\n",
        "\n",
        "stage2_model = train_step2_pretraining(train_cfg, alm_cfg, stage1_model)\n",
        "final_model = train_step3_instruction_tuning(train_cfg, alm_cfg, stage2_model)\n",
        "# stage1_model, stage2_model, final_model = train_three_stages(train_cfg, alm_cfg)\n",
        "\n",
        "stage1_model.save_pretrained(\"/content/\")\n",
        "stage2_model.save_pretrained(\"/content/\")\n",
        "final_model.save_pretrained(\"/content/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VHmI2cQ28RAj",
      "metadata": {
        "id": "VHmI2cQ28RAj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78d938dd",
      "metadata": {
        "id": "78d938dd"
      },
      "source": [
        "As you can see the model trains, so feel free to play around with the architecture or data! Let us know what you build with it!\n",
        "\n",
        "PS: If you want to test the model, check out generate.py to see how to do inference with it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mZWoCjkGGfMQ",
      "metadata": {
        "id": "mZWoCjkGGfMQ"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kjOsHkjpCoYp",
      "metadata": {
        "id": "kjOsHkjpCoYp"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/nanoALM/output_txt1.wav /content/output_txt1.wav\n",
        "!cp /content/drive/MyDrive/nanoALM/output_txt2.wav /content/output_txt2.wav\n",
        "!cp /content/drive/MyDrive/nanoALM/output_txt3.wav /content/output_txt3.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07dM8znZPTSj",
      "metadata": {
        "id": "07dM8znZPTSj"
      },
      "outputs": [],
      "source": [
        "!cp ../model.safetensors /content/drive/MyDrive/nanoALM/model.safetensors\n",
        "!cp ../config.json /content/drive/MyDrive/nanoALM/config.json\n",
        "!cp ./model.safetensors /content/drive/MyDrive/nanoALM\n",
        "!cp ./config.json /content/drive/MyDrive/nanoALM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RSbBheB3HGns",
      "metadata": {
        "collapsed": true,
        "id": "RSbBheB3HGns"
      },
      "outputs": [],
      "source": [
        "# final_model.save_pretrained(\"/content/\")\n",
        "!python generate.py --checkpoint ../ --audio ../output_txt1.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FN6ra31lP8QM",
      "metadata": {
        "collapsed": true,
        "id": "FN6ra31lP8QM"
      },
      "outputs": [],
      "source": [
        "!python generate.py --checkpoint ../ --audio ../output_txt2.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eo_p1E3xP8gd",
      "metadata": {
        "collapsed": true,
        "id": "eo_p1E3xP8gd"
      },
      "outputs": [],
      "source": [
        "!python generate.py --checkpoint ../ --audio ../output_txt3.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T0cMUB4lb4zR",
      "metadata": {
        "id": "T0cMUB4lb4zR"
      },
      "outputs": [],
      "source": [
        "!python generate.py --checkpoint ../ --audio ../output_txt3.wav"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

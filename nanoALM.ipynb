{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2de5dd1f",
      "metadata": {
        "id": "2de5dd1f"
      },
      "source": [
        "### Train a ALM in Google Colab!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OCooV08mNANR",
      "metadata": {
        "id": "OCooV08mNANR"
      },
      "source": [
        "### Clone the repository if you don't have it already"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ooQMjmrMLn-4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooQMjmrMLn-4",
        "outputId": "c2418b12-042c-476f-d010-6634977f9002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'nanoVLM_From_Huggingface' already exists and is not an empty directory.\n",
            "/content/nanoVLM_From_Huggingface\n",
            "assets\t\t\tdebug_tokenizer_dataset_compatibility.py\n",
            "benchmark-inference.py\tgenerate.py\n",
            "benchmark_suite.py\tmeasure_vram.py\n",
            "checkpoints\t\tmodels\n",
            "compare1.py\t\tnanoALM.ipynb\n",
            "compare2.py\t\tREADME.md\n",
            "data\t\t\ttrain.py\n",
            "debug_func.py\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('nanoALM'):\n",
        "    !git clone https://github.com/LWL220184016/nanoVLM_From_Huggingface.git\n",
        "%cd nanoVLM_From_Huggingface/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mMhc9OCENup5",
      "metadata": {
        "id": "mMhc9OCENup5"
      },
      "source": [
        "### Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54bc8463",
      "metadata": {
        "id": "54bc8463",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3d261d-16eb-4a02-a332-7367efeb7589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `for get model` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `for get model`\n"
          ]
        }
      ],
      "source": [
        "# Let's authentificate with the Hugging Face Hub so you can push your model\n",
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()\n",
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcw8qQqoOSR7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bcw8qQqoOSR7",
        "outputId": "f4ddc3c8-e594-44e6-e674-66c3cd9087fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2025.3.0\n"
          ]
        }
      ],
      "source": [
        "# If you get an \"Error\" from pip's dependency resolver but the cell complets fine, this is not an issue, you can continue :)\n",
        "!pip -q install torch\n",
        "!pip -q install gcsfs\n",
        "!pip -q install tqdm\n",
        "!pip -q install huggingface_hub\n",
        "!pip -q install librosa\n",
        "!pip install --upgrade datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e8dc5ba",
      "metadata": {
        "id": "5e8dc5ba"
      },
      "outputs": [],
      "source": [
        "# Decide on the name of your model here!\n",
        "# You will need your HF user name and the name you want to give to it\n",
        "# For me, this would be \"lusxvr/nanoALM\"\n",
        "# hf_model_name = \"YOUR_HF_USER_NAME/nanoALM\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OTsl1jZrMeaJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTsl1jZrMeaJ",
        "outputId": "b830f10f-c530-473f-8982-f1c65287edcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# nanoALM Imports (please check out the implementations in detail, that's where all the interessting stuff is!)\n",
        "from data.collators import AudioQACollator, SAVEECollator\n",
        "from data.datasets import SAVEEDataset, AudioQADataset\n",
        "from data.processors import get_audio_processor\n",
        "from data.processors import get_tokenizer\n",
        "from models.audio_language_model import AudioLanguageModel\n",
        "import models.utils as utils\n",
        "\n",
        "# Libraries\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "#Otherwise, the tokenizer will through a warning\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "trained_model = None\n",
        "\n",
        "# To reload the modules if you change something in the code\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4Vzo03IzN3Zf",
      "metadata": {
        "id": "4Vzo03IzN3Zf"
      },
      "source": [
        "### Get the dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3Zzn2FI2N7Aj",
      "metadata": {
        "id": "3Zzn2FI2N7Aj"
      },
      "outputs": [],
      "source": [
        "def get_dataloaders(train_cfg, alm_cfg):\n",
        "    # Create datasets\n",
        "    audio_processor = get_audio_processor(alm_cfg.audio_sample_rate)\n",
        "    tokenizer = get_tokenizer(alm_cfg.lm_tokenizer)\n",
        "\n",
        "    # text = \"splitting datasets, disable in get_dataloaders function\"\n",
        "    # print(f\"\\n\\033[38;5;05m{text}05m\\033[0m\")\n",
        "    # Load and combine all training datasets\n",
        "    combined_train_data = []\n",
        "    for dataset_name in train_cfg.train_dataset_name:\n",
        "        train_ds = load_dataset(\n",
        "        path = train_cfg.train_dataset_path,\n",
        "        name = dataset_name,\n",
        "        # split='train[:1000]'\n",
        "    )\n",
        "        combined_train_data.append(train_ds['train'])\n",
        "    train_ds = concatenate_datasets(combined_train_data)\n",
        "\n",
        "    test_ds = load_dataset(train_cfg.test_dataset_path)\n",
        "    train_ds = train_ds.shuffle(seed=0) # Shuffle the training dataset, so train and val get equal contributions from all concatinated datasets\n",
        "\n",
        "    # Apply cutoff if specified\n",
        "    if train_cfg.data_cutoff_idx is None:\n",
        "        total_samples = len(train_ds)  # Use the entire dataset\n",
        "    else:\n",
        "        total_samples = min(len(train_ds), train_cfg.data_cutoff_idx)\n",
        "\n",
        "    val_size = int(total_samples * train_cfg.val_ratio)\n",
        "    train_size = total_samples - val_size\n",
        "\n",
        "    train_dataset = AudioQADataset(train_ds.select(range(train_size)), tokenizer, audio_processor)\n",
        "    val_dataset = AudioQADataset(train_ds.select(range(train_size, total_samples)), tokenizer, audio_processor)\n",
        "    test_dataset = SAVEEDataset(test_ds, tokenizer, audio_processor)\n",
        "\n",
        "    # Create collators\n",
        "    aqa_collator = AudioQACollator(tokenizer, alm_cfg.lm_max_length)\n",
        "    savee_collator = SAVEECollator(tokenizer)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=train_cfg.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=aqa_collator,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=train_cfg.batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=aqa_collator,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=train_cfg.savee_batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=savee_collator,\n",
        "        pin_memory=True,\n",
        "        )\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D7NIuEDuOuuJ",
      "metadata": {
        "id": "D7NIuEDuOuuJ"
      },
      "source": [
        "### Prepare the testing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fnh6wOlOzat",
      "metadata": {
        "id": "9fnh6wOlOzat"
      },
      "outputs": [],
      "source": [
        "def test_savee(model, tokenizer, test_loader, device):\n",
        "    total_examples = 0\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            audio = batch['audios'].to(device)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            correct_answer = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "            gen = model.generate(input_ids, audio, attention_mask)\n",
        "            model_output = tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
        "\n",
        "            is_correct = utils.check_multiple_choice_with_regex(model_output, correct_answer)\n",
        "\n",
        "            total_examples += len(is_correct)\n",
        "            if is_correct:\n",
        "                correct_predictions += sum(is_correct)\n",
        "    accuracy = correct_predictions / total_examples if total_examples > 0 else 0\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe359194",
      "metadata": {
        "id": "fe359194"
      },
      "source": [
        "### Add debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d7b7e46",
      "metadata": {
        "id": "5d7b7e46"
      },
      "outputs": [],
      "source": [
        "# 在训练开始前添加这个检查函数\n",
        "def debug_model_dimensions(model, input_ids, audio):\n",
        "    \"\"\"调试模型各层的维度\"\"\"\n",
        "    print(\"=== Model Dimension Debug ===\")\n",
        "\n",
        "    # 检查音频编码器\n",
        "    audio_features = model.audio_encoder(audio)\n",
        "    print(f\"Audio features shape: {audio_features.shape}\")\n",
        "\n",
        "    # 检查模态投影器\n",
        "    audio_embeds = model.MP(audio_features)\n",
        "    print(f\"Audio embeds shape: {audio_embeds.shape}\")\n",
        "\n",
        "    # 检查文本嵌入\n",
        "    text_embeds = model.decoder.token_embedding(input_ids)\n",
        "    print(f\"Text embeds shape: {text_embeds.shape}\")\n",
        "\n",
        "    # 检查拼接后的嵌入\n",
        "    inputs_embeds = torch.cat([audio_embeds, text_embeds], dim=1)\n",
        "    print(f\"Combined embeds shape: {inputs_embeds.shape}\")\n",
        "\n",
        "    # 检查语言模型输出\n",
        "    logits = model.decoder(inputs_embeds)\n",
        "    print(f\"Logits shape: {logits.shape}\")\n",
        "    print(f\"Vocab size (last dim): {logits.shape[-1]}\")\n",
        "\n",
        "    # 检查语言模型配置\n",
        "    print(f\"LM vocab size config: {model.cfg.lm_vocab_size}\")\n",
        "    print(f\"Decoder vocab size: {getattr(model.decoder, 'vocab_size', 'Not found')}\")\n",
        "\n",
        "    return logits.shape[-1]\n",
        "\n",
        "# 在训练循环开始前调用\n",
        "# vocab_size = debug_model_dimensions(model, input_ids, audios)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d48d0df",
      "metadata": {
        "id": "2d48d0df"
      },
      "outputs": [],
      "source": [
        "def debug_training_step(model, input_ids, audios, attention_mask, labels):\n",
        "    \"\"\"调试训练步骤\"\"\"\n",
        "    # 添加这些调试行：\n",
        "    print(f\"Batch debug - input_ids shape: {input_ids.shape}, max: {input_ids.max().item()}\")\n",
        "    print(f\"Batch debug - labels shape: {labels.shape}, max: {labels.max().item()}\")\n",
        "    print(f\"Batch debug - Model vocab config: {model.cfg.lm_vocab_size}\")\n",
        "\n",
        "    # 检查decoder的实际vocab_size\n",
        "    if hasattr(model.decoder, 'head') and hasattr(model.decoder.head, 'out_features'):\n",
        "        print(f\"Decoder head in_features: {model.decoder.head.in_features}\")\n",
        "        print(f\"Decoder head out_features: {model.decoder.head.out_features}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_F8u3MJ6PAfd",
      "metadata": {
        "id": "_F8u3MJ6PAfd"
      },
      "source": [
        "### Prepare the training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "KxOtMU5zPD-4",
      "metadata": {
        "id": "KxOtMU5zPD-4"
      },
      "outputs": [],
      "source": [
        "def get_lr(it, max_lr, max_steps):\n",
        "    min_lr = max_lr * 0.1\n",
        "    warmup_steps = max_steps * 0.03\n",
        "    # 1) linear warmup for warmup_iters steps\n",
        "    if it < warmup_steps:\n",
        "        return max_lr * (it+1) / warmup_steps\n",
        "    # 2) if it > lr_decay_iters, return min learning rate\n",
        "    if it > max_steps:\n",
        "        return min_lr\n",
        "    # 3) in between, use cosine decay down to min learning rate\n",
        "    decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff starts at 1 and goes to 0\n",
        "    return min_lr + coeff * (max_lr - min_lr)\n",
        "\n",
        "def train(train_cfg, alm_cfg):\n",
        "    train_loader, val_loader, test_loader = get_dataloaders(train_cfg, alm_cfg)\n",
        "    tokenizer = get_tokenizer(alm_cfg.lm_tokenizer)\n",
        "\n",
        "    # Initialize model\n",
        "    if train_cfg.resume_from_alm_checkpoint:\n",
        "        model = AudioLanguageModel.from_pretrained(alm_cfg.alm_checkpoint_path)\n",
        "    else:\n",
        "        model = AudioLanguageModel(alm_cfg)\n",
        "\n",
        "    print(f\"nanoALM initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "    print(f\"Training summary: {len(train_loader.dataset)} samples, {len(train_loader)} batches/epoch, batch size {train_cfg.batch_size}\")\n",
        "\n",
        "    # Define optimizer groups\n",
        "    param_groups = [{'params': model.MP.parameters(), 'lr': train_cfg.lr_mp},\n",
        "                    {'params': list(model.decoder.parameters()) + list(model.audio_encoder.parameters()), 'lr': train_cfg.lr_backbones}]\n",
        "    optimizer = optim.AdamW(param_groups)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    if train_cfg.compile:\n",
        "        model = torch.compile(model)\n",
        "\n",
        "    epoch_times = []\n",
        "    batch_losses = []\n",
        "    val_losses = []\n",
        "    val_plot_steps = []\n",
        "    best_accuracy = 0\n",
        "    global_step = 0\n",
        "    for epoch in range(train_cfg.epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        total_tokens_processed = 0\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "            batch_start_time = time.time()\n",
        "            audios = batch[\"audio\"].to(device)\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            # debug_model_dimensions(model, input_ids, audios)  # Debug model dimensions with dummy data\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.autocast(device_type='cuda', dtype=torch.float16): # Mixed precision training\n",
        "                # debug_training_step(model, input_ids, audios, attention_mask, labels)  # Debug training step\n",
        "                _, loss = model(input_ids, audios, attention_mask=attention_mask, targets=labels)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            adj_lr_mp = get_lr(global_step, train_cfg.lr_mp, len(train_loader) * train_cfg.epochs)\n",
        "            adj_lr_backbones = get_lr(global_step, train_cfg.lr_backbones, len(train_loader) * train_cfg.epochs)\n",
        "            optimizer.param_groups[0]['lr'] = adj_lr_mp\n",
        "            optimizer.param_groups[1]['lr'] = adj_lr_backbones\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_loss = loss.item()\n",
        "            total_train_loss += batch_loss\n",
        "            batch_losses.append(batch_loss)\n",
        "\n",
        "            num_tokens = torch.sum(attention_mask).item()\n",
        "            # 修改音頻token計算：根據實際的音頻處理方式\n",
        "            audio_tokens = audios.shape[0] * alm_cfg.mp_target_length  # 使用配置的目標長度\n",
        "            num_tokens += audio_tokens\n",
        "            total_tokens_processed += num_tokens\n",
        "\n",
        "            batch_end_time = time.time()\n",
        "            batch_duration = batch_end_time - batch_start_time\n",
        "            tokens_per_second = num_tokens / batch_duration\n",
        "\n",
        "            if global_step % 5 == 0:\n",
        "                model.eval()\n",
        "                torch.cuda.empty_cache()  # Clear GPU memory\n",
        "                with torch.no_grad():\n",
        "                    total_val_loss = 0\n",
        "                    for batch in val_loader:\n",
        "                        audios = batch[\"audio\"].to(device)\n",
        "                        input_ids = batch[\"input_ids\"].to(device)\n",
        "                        labels = batch[\"labels\"].to(device)\n",
        "                        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "                        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                            # debug_training_step(model, input_ids, audios, attention_mask, labels)  # Debug training step\n",
        "                            _, loss = model(input_ids, audios, attention_mask=attention_mask, targets=labels)\n",
        "\n",
        "                        total_val_loss += loss.item()\n",
        "                    avg_val_loss = total_val_loss / len(val_loader)\n",
        "                    val_losses.append(avg_val_loss)\n",
        "                    val_plot_steps.append(global_step)\n",
        "                epoch_accuracy = 0\n",
        "                if train_cfg.eval_in_epochs:\n",
        "                    epoch_accuracy = test_savee(model, tokenizer, test_loader, device)\n",
        "                    if epoch_accuracy > best_accuracy:\n",
        "                      best_accuracy = epoch_accuracy\n",
        "                      model.save_pretrained(save_directory=alm_cfg.alm_checkpoint_path)\n",
        "                    print(f\"\\nStep: {global_step}, Loss: {batch_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Tokens/s: {tokens_per_second:.2f}, Accuracy: {epoch_accuracy:.4f}\")\n",
        "                model.train()\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_duration = epoch_end_time - epoch_start_time\n",
        "        epoch_times.append(epoch_duration)\n",
        "\n",
        "        epoch_tokens_per_second = total_tokens_processed / epoch_duration\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{train_cfg.epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Time: {epoch_duration:.2f}s | T/s: {epoch_tokens_per_second:.2f}\")\n",
        "\n",
        "    # Summary Statistics\n",
        "    if not train_cfg.eval_in_epochs:\n",
        "        model.save_pretrained(save_directory=alm_cfg.alm_checkpoint_path)\n",
        "    try:\n",
        "        model.push_to_hub(hf_model_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error pushing model to hub: {e}\")\n",
        "\n",
        "    avg_epoch_time = sum(epoch_times) / len(epoch_times)\n",
        "    total_training_time = sum(epoch_times)\n",
        "    total_samples_processed = len(train_loader.dataset) * train_cfg.epochs\n",
        "    avg_time_per_sample = total_training_time / total_samples_processed\n",
        "    print(f\"Average time per epoch: {avg_epoch_time:.2f}s\")\n",
        "    print(f\"Average time per sample: {avg_time_per_sample:.4f}s\")\n",
        "\n",
        "    plt.plot(batch_losses, label='Train Loss')\n",
        "    plt.plot(val_plot_steps, val_losses, label='Val Loss')\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Curve')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "    # With this code you can test the accuracy of the model on the SAVEE dataset\n",
        "    # But if you only train with few samples, the accuracy will be very low\n",
        "    # print(\"Testing SAVEE Accuracy:\")\n",
        "    # accuracy = test_savee(model, tokenizer, test_loader, device)\n",
        "    # print(f\"SAVEE Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4HmsEPNQZbh",
      "metadata": {
        "id": "d4HmsEPNQZbh"
      },
      "source": [
        "### Prepare the Configs\n",
        "Instead of using the config.py file in the repo (which was created to run on one H100), we will create our config here to play around with the parameters easier and adapt them to colabs capabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h8FlqtizQdO-",
      "metadata": {
        "id": "h8FlqtizQdO-"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ALMConfig:\n",
        "    audio_hidden_dim: int = 768\n",
        "    audio_inter_dim: int = 4 * audio_hidden_dim\n",
        "    audio_patch_size: int = 16  # 音频patch大小（时间步数）\n",
        "    audio_n_heads: int = 12\n",
        "    audio_dropout: float = 0.0\n",
        "    audio_n_blocks: int = 12\n",
        "    audio_ln_eps: float = 1e-6\n",
        "    audio_model_type: str = 'custom_audio_transformer'\n",
        "\n",
        "    # 音频处理相关参数\n",
        "    audio_sample_rate: int = 16000  # 采样率\n",
        "    audio_n_fft: int = 400  # FFT窗口大小\n",
        "    audio_hop_length: int = 160  # 跳跃长度\n",
        "    audio_n_mels: int = 80  # 梅尔滤波器数量\n",
        "    audio_max_length: int = 1000  # 最大时间步数\n",
        "\n",
        "    lm_hidden_dim: int = 576\n",
        "    lm_inter_dim: int = 1536\n",
        "    lm_rms_eps: float = 1e-5\n",
        "    lm_re_base: int = 100000\n",
        "    lm_max_position_embeddings: int = 8192\n",
        "    lm_vocab_size: int = 49152\n",
        "    lm_n_heads: int = 9\n",
        "    lm_n_kv_heads: int = 3\n",
        "    lm_dropout: float = 0.0\n",
        "    lm_n_blocks: int = 30\n",
        "    lm_attn_scaling: float = 1.0\n",
        "    lm_eos_token_id: int = 0\n",
        "    lm_use_tokens: bool = False\n",
        "    lm_tie_weights: bool = True\n",
        "    lm_model_type: str = 'HuggingFaceTB/SmolLM2-135M'\n",
        "    lm_tokenizer: str = 'HuggingFaceTB/cosmo2-tokenizer'\n",
        "\n",
        "    # 模態投影器配置\n",
        "    mp_projection_type: str = 'adaptive_pool'\n",
        "    mp_target_length: int = 50\n",
        "    mp_use_position_aware: bool = True\n",
        "\n",
        "    # 計算語言模型最大長度\n",
        "    lm_max_length: int = 128 - 50  # 總長度 - 音頻token長度\n",
        "\n",
        "    # ALM特定配置\n",
        "    alm_load_backbone_weights: bool = True\n",
        "    alm_checkpoint_path: str = 'checkpoints'\n",
        "    alm_name: str = 'nanoALM-222M'\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    lr_mp: float = 1e-5\n",
        "    lr_backbones: float = 5e-7\n",
        "    val_ratio: float = 0.2\n",
        "    compile: bool = False\n",
        "    data_cutoff_idx: int = 1024 # Let's only use a small subset of the data at first, otherwise it takes very long to see anything :D\n",
        "    batch_size: int = 12\n",
        "    savee_batch_size: int = 12\n",
        "    epochs: int = 20\n",
        "    eval_in_epochs: bool = False # Deactivating this in colab, because it would evaluate 1500 samples of SAVEE every time otherwise\n",
        "    resume_from_alm_checkpoint: bool = False # Indicate if the training should be resumed from a checkpoint of the whole ALM or you want to start from scratch\n",
        "\n",
        "    # train_dataset_path: str = 'AbstractTTS/IEMOCAP'\n",
        "    # train_dataset_name: tuple[str, ...] = ('default', ) #All options; (\"ai2d\", \"aokvqa\", \"chart2text\", \"chartqa\", \"clevr\", \"cocoqa\", \"datikz\", \"diagram_image_to_text\", \"docvqa\", \"dvqa\", \"figureqa\", \"finqa\", \"geomverse\", \"hateful_memes\", \"hitab\", \"iam\", \"iconqa\", \"infographic_vqa\", \"intergps\", \"localized_narratives\", \"mapqa\", \"multihiertt\", \"ocrvqa\", \"plotqa\", \"raven\", \"rendered_text\", \"robut_sqa\", \"robut_wikisql\", \"robut_wtq\", \"scienceqa\", \"screen2words\", \"st_vqa\", \"tabmwp\", \"tallyqa\", \"tat_qa\", \"textcaps\", \"textvqa\", \"tqa\", \"vistext\", \"visual7w\", \"visualmrc\", \"vqarad\", \"vqav2\", \"vsr\", \"websight\") # \"clevr_math\", \"okvqa\", \"spot_the_diff\", \"nlvr2\", \"mimic_cgd\",\n",
        "\n",
        "    # train_dataset_path: str = 'speechbrain/LoquaciousSet'\n",
        "    # train_dataset_name: tuple[str, ...] = ('medium', ) # small, medium\n",
        "\n",
        "    train_dataset_path: str = 'MLCommons/peoples_speech'\n",
        "    train_dataset_name: tuple[str, ...] = ('clean_sa', ) # small, medium\n",
        "    test_dataset_path: str = \"AbstractTTS/SAVEE\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KmFQwKGcSLr_",
      "metadata": {
        "id": "KmFQwKGcSLr_"
      },
      "source": [
        "### Lets run the training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BXUaUEUcJCp2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXUaUEUcJCp2",
        "outputId": "58cee99d-ab31-48cb-e55e-2dc3a64ee7f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'checkpoints' already exists.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# 要創建的目錄路徑\n",
        "dir_name = ALMConfig.alm_checkpoint_path\n",
        "\n",
        "try:\n",
        "    os.mkdir(dir_name)\n",
        "    print(f\"Directory '{dir_name}' created successfully.\")\n",
        "except FileExistsError:\n",
        "    print(f\"Directory '{dir_name}' already exists.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Parent directory does not exist for '{dir_name}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9MlFpXQFSNdx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408,
          "referenced_widgets": [
            "a69c9391e53d42dc8b1a8c1c73886e21",
            "50667bb8f5da418d813a7be605e04eb8",
            "05fae3c020b7430fac0b54789ebed9c9",
            "7c7f7fa6f8c7468a90eec7f2366b9aca",
            "3845f5ad682f490281e825909b3d500d",
            "7408c0a666c34df9a6b2cdc632b25d27",
            "95ab0ddb017847d787a6ac2fae723cb8",
            "85edd1103a5b4e9a8f044b5d3c62ab26",
            "bbc0f342fd37417fabc77b26669de3f4",
            "00b5bd57b1294d9187f7e3ce913c91de",
            "245556f8a2c64259b8bf0cb843a0a39a",
            "1d2b0bb0672c47c7ac7938e68fb6979d",
            "95b2a138a27d4174bb63c13d8b64725f",
            "4a2faacaac5b428ead374d8130207e0d",
            "dcb6dd2cbf55428d9a3178d4ee6b03d7",
            "5eb9b55409ef4fb6b1a668736068354a",
            "3344a0fce65c4395ad6f4cfc8fc264e6",
            "5549d515761244dbb93ee102c3e081ed",
            "8caf47921b4d4870841dba6fc0001323",
            "638fa01ed48c4114b09c08c7f1fb88ff",
            "095820abc0c548529cfab1e5d916492e",
            "f2770b7a4fa14dc0bd4c770d898231d8",
            "755296b1b45945fcbb80e6f31c1932b0",
            "a9bfc91fb83240219b270543076113b5",
            "87a136e26c2943419c234c2b451fc7b4",
            "2e14c1ecef4b4d2a82be50cf1d20f98a",
            "d762498f26764a2c86b21dce88747b5e",
            "03194fed613c4ed5b88ee46234506066",
            "9b25160371a0461096dc6531209242b3",
            "6dd40853576a499b9294f1869cce9771",
            "ec5ae08e406d4cc8a3a66b81aa63b704",
            "7cbe394de4164baeb3a1896ccea7f20c",
            "b695aed8d8b4448f85bd35e29347f501"
          ]
        },
        "collapsed": true,
        "id": "9MlFpXQFSNdx",
        "outputId": "ea88b396-1ddc-41dc-fc0b-800cad953b53"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/804 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a69c9391e53d42dc8b1a8c1c73886e21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/151 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d2b0bb0672c47c7ac7938e68fb6979d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading dataset shards:   0%|          | 0/133 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "755296b1b45945fcbb80e6f31c1932b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading from backbone weights\n",
            "Initializing AudioTransformer from scratch with custom_audio_transformer\n",
            "AudioTransformer initialized with 86,087,424 parameters.\n",
            "Successfully loaded HuggingFaceTB/SmolLM2-135M weights from safetensors. Model has 134,515,008 parameters.\n",
            "nanoALM initialized with 221,044,800 parameters\n",
            "Training summary: 820 samples, 68 batches/epoch, batch size 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/68 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Debugging batch data:\n",
            "Audios min: -0.98760986328125, max: 0.999969482421875, has_nan: False\n",
            "Input IDs min: 0, max: 48477, has_nan: False\n",
            "Labels min: -100, max: -100, has_nan: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 68/68 [03:31<00:00,  3.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | Train Loss: nan | Val Loss: nan | Time: 211.96s | T/s: 392.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 68/68 [03:28<00:00,  3.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20 | Train Loss: nan | Val Loss: nan | Time: 208.77s | T/s: 398.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 68/68 [03:29<00:00,  3.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20 | Train Loss: nan | Val Loss: nan | Time: 209.27s | T/s: 397.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 1/68 [00:02<02:18,  2.06s/it]"
          ]
        }
      ],
      "source": [
        "alm_cfg = ALMConfig()\n",
        "train_cfg = TrainConfig()\n",
        "trained_model = train(train_cfg, alm_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78d938dd",
      "metadata": {
        "id": "78d938dd"
      },
      "source": [
        "As you can see the model trains, so feel free to play around with the architecture or data! Let us know what you build with it!\n",
        "\n",
        "PS: If you want to test the model, check out generate.py to see how to do inference with it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tn3F8DfCkuk8",
      "metadata": {
        "id": "tn3F8DfCkuk8"
      },
      "outputs": [],
      "source": [
        "trained_model.save_pretrained(\"/content/\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a69c9391e53d42dc8b1a8c1c73886e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50667bb8f5da418d813a7be605e04eb8",
              "IPY_MODEL_05fae3c020b7430fac0b54789ebed9c9",
              "IPY_MODEL_7c7f7fa6f8c7468a90eec7f2366b9aca"
            ],
            "layout": "IPY_MODEL_3845f5ad682f490281e825909b3d500d"
          }
        },
        "50667bb8f5da418d813a7be605e04eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7408c0a666c34df9a6b2cdc632b25d27",
            "placeholder": "​",
            "style": "IPY_MODEL_95ab0ddb017847d787a6ac2fae723cb8",
            "value": "Resolving data files: 100%"
          }
        },
        "05fae3c020b7430fac0b54789ebed9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85edd1103a5b4e9a8f044b5d3c62ab26",
            "max": 804,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbc0f342fd37417fabc77b26669de3f4",
            "value": 804
          }
        },
        "7c7f7fa6f8c7468a90eec7f2366b9aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00b5bd57b1294d9187f7e3ce913c91de",
            "placeholder": "​",
            "style": "IPY_MODEL_245556f8a2c64259b8bf0cb843a0a39a",
            "value": " 804/804 [00:00&lt;00:00, 12.49it/s]"
          }
        },
        "3845f5ad682f490281e825909b3d500d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7408c0a666c34df9a6b2cdc632b25d27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95ab0ddb017847d787a6ac2fae723cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85edd1103a5b4e9a8f044b5d3c62ab26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbc0f342fd37417fabc77b26669de3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00b5bd57b1294d9187f7e3ce913c91de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "245556f8a2c64259b8bf0cb843a0a39a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d2b0bb0672c47c7ac7938e68fb6979d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95b2a138a27d4174bb63c13d8b64725f",
              "IPY_MODEL_4a2faacaac5b428ead374d8130207e0d",
              "IPY_MODEL_dcb6dd2cbf55428d9a3178d4ee6b03d7"
            ],
            "layout": "IPY_MODEL_5eb9b55409ef4fb6b1a668736068354a"
          }
        },
        "95b2a138a27d4174bb63c13d8b64725f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3344a0fce65c4395ad6f4cfc8fc264e6",
            "placeholder": "​",
            "style": "IPY_MODEL_5549d515761244dbb93ee102c3e081ed",
            "value": "Resolving data files: 100%"
          }
        },
        "4a2faacaac5b428ead374d8130207e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8caf47921b4d4870841dba6fc0001323",
            "max": 151,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_638fa01ed48c4114b09c08c7f1fb88ff",
            "value": 151
          }
        },
        "dcb6dd2cbf55428d9a3178d4ee6b03d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_095820abc0c548529cfab1e5d916492e",
            "placeholder": "​",
            "style": "IPY_MODEL_f2770b7a4fa14dc0bd4c770d898231d8",
            "value": " 151/151 [00:00&lt;00:00, 14618.35it/s]"
          }
        },
        "5eb9b55409ef4fb6b1a668736068354a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3344a0fce65c4395ad6f4cfc8fc264e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5549d515761244dbb93ee102c3e081ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8caf47921b4d4870841dba6fc0001323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "638fa01ed48c4114b09c08c7f1fb88ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "095820abc0c548529cfab1e5d916492e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2770b7a4fa14dc0bd4c770d898231d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "755296b1b45945fcbb80e6f31c1932b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9bfc91fb83240219b270543076113b5",
              "IPY_MODEL_87a136e26c2943419c234c2b451fc7b4",
              "IPY_MODEL_2e14c1ecef4b4d2a82be50cf1d20f98a"
            ],
            "layout": "IPY_MODEL_d762498f26764a2c86b21dce88747b5e"
          }
        },
        "a9bfc91fb83240219b270543076113b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03194fed613c4ed5b88ee46234506066",
            "placeholder": "​",
            "style": "IPY_MODEL_9b25160371a0461096dc6531209242b3",
            "value": "Loading dataset shards: 100%"
          }
        },
        "87a136e26c2943419c234c2b451fc7b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dd40853576a499b9294f1869cce9771",
            "max": 133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec5ae08e406d4cc8a3a66b81aa63b704",
            "value": 133
          }
        },
        "2e14c1ecef4b4d2a82be50cf1d20f98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cbe394de4164baeb3a1896ccea7f20c",
            "placeholder": "​",
            "style": "IPY_MODEL_b695aed8d8b4448f85bd35e29347f501",
            "value": " 133/133 [00:00&lt;00:00, 2103.90it/s]"
          }
        },
        "d762498f26764a2c86b21dce88747b5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03194fed613c4ed5b88ee46234506066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b25160371a0461096dc6531209242b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dd40853576a499b9294f1869cce9771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec5ae08e406d4cc8a3a66b81aa63b704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cbe394de4164baeb3a1896ccea7f20c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b695aed8d8b4448f85bd35e29347f501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}